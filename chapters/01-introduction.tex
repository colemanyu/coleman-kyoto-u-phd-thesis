\chapter{Introduction} \label{ch:introduction}
\section{Background}
Human generates a ton of data nowadays.
We are producing more new data in one single day today than in the first twenty-one centuries of AD combined.
We are drowning in information but thirsty for knowledge.
It is natural for us to develop computational methods to accelerate the process of ``harvesting'' knowledge from information.

Computational tasks focus on the relationship between input and output.
We would like to find the hidden function behind.
To note, there are two ways to solve a problem. One is the algorithmic approach, and the other is the machine-learning approach.
In Chapter~\ref{ch:mtsccleav}, it demonstrates a machine learning approach to analyze a biology problem.
In Chapter~\ref{ch:ksfdtw}, we solve an algorithmic problem on distance measure.

There are two large categories of machine learning.
They are supervised learning and unsupervised learning.
Classification may be the most intuitive form of supervised learning.
The input is data points with labels. We learn a model from the relationship between data points and the labels. The model predicts the labels for the new data points.
They have many applications. For example, in medical applications, it involves classifying patients as healthy or diseased, or tumors as benign or malignant.
The term ``supervised'' means the model has access to labeled data.
In other words, it requires labeled training examples that provide ground truth. So, the model can learn the boundary between the categories.
Our first study focuses on a classification problem in biology.

A representative of unsupervised learning is undoubtedly clustering. We aim to group data into distinct clusters. The key difference is that the data lack predefined labels. By grouping them, we aim to identify natural patterns hidden in the data.
One example is clustering cells based on their gene-expression profiles. These clusters might reveal distinct cell types. Note that we do not have the ground truth for the cluster set. 
In bioinformatics, we typically use enrichment analysis to determine whether specific gene functions are enriched in these clusters.
Cell types often show enrichment for genes responsible for specific functions. This set of genes defines their biological role. 
In clustering, we first need to define a measure of similarity between two objects. And what should be ignored. This is called invariance. For example, in image classification, it should be invariant with respect to the zooming effect and the rotation effect.
In Chapter~\ref{ch:ksfdtw}, we define a new distance measure framework that achieves invaraince when two time series are in different scaling factors.

% What is a computational problem
% What is Bioinformatics
% What is data mining
% Thinking in primitive 

\section{Contributions}
In this study, our contributions mainly include two parts.
First, we propose the usage of the base pair probability sequence from the predicted secondary structure of RNA sequence as a new information for the classification task. We apply Rocket-based classifiers to identify the human dicer cleavage sites.
Because of the simplicity of the transformation method and the classifiers, our proposed method achieves 3.7X to 28.8X speedup while achieving better or comparable results than the current state-of-the-art method.
Second, we propose a new distance measure framework, namely PSD, that can incorporate any existing distance measures to achieve invariance for two time series with multiple rates.
Experiments show that our methods outperform ED, DTW and the other five DTW-based methods.
Besides, we propose to use the segmentation result returned by PSD to improve the accuracy of other distance measures.
Third, we propose leveraging left nearest neighbors for each forecasting window as new covariates to improve the accuracy of the underlying forecaster.
We use a simple gradient boosting regression tree as the underlying forecaster.
Experiment shows that this simple method can imrpove the accuracy.

\section{Organization}
In Chapter~\ref{ch:preliminaries}, we review some of the basic knowledge in biology and time series data mining, in particular, we focus on distance measures and Rocket-based classifiers.
In Chapter~\ref{ch:mtsccleav}, we introduce our study of the problem of predicting human dicer cleavage sites. We proposed a novel approach to frame this task as a multivariate time series classification problem by introducing nine encoding methods and making use of Rocket-based classifiers.
In Chapter~\ref{ch:ksfdtw}, we introduce a new distance measure framework, namely PSD. It releases the assumption that there is only one scaling factor existing throughout the whole time series.
In Chapter~\ref{ch:mpmf}, we introduce how to create new covariates in time series forecasting using matrix profile.
This method can improve the accuracy of the existing forecaster by providing useful covariates.
In Chapter~\ref{ch:conclusion}, we give a conclusion to these two studies and provide future work on them.



