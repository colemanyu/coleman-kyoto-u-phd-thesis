\section{Piecewise Scaling Distance} \label{sec:method}

The motivation stems from the limitations of US and USDTW.
They assume that the relationship between $Q$ and $C$ is governed by only a single, global scaling factor. 
This assumption fails when applied to multi-rate data, where different phases of the time series express at different rates.

Note that existing studies~\cite{keogh2004indexing, rakthanmanon2013addressing} can find all scaling factors, defined by the chosen prefix of $C$, ranging from $\ceil{m/l}$ to $min(\floor{lm}, n)$. 
However, they can use only one of them in the scaling.
Consider the following illustrative example in ASCII text~\cite{rakthanmanon2013addressing}, where character repetition represents the duration of spoken phonemes, and space indicates a pause:
\begin{itemize}
    \item ``time~\quad~series 20 25'' and ``time~\underline{series\quad}~20 25''. Here, the Hamming distance (the discrete analogue of ED) fails due to misalignment in the underlined locations, but the string edit distance (the discrete analogue of DTW) can resolve it.
    \item ``time~\underline{sseerriiss~222000222555}''.This sequence exhibits three distinct phases with scaling factors of 1, 2, and 3, respectively. 
    The corresponding invariance cannot be achieved by DTW or US (which is restricted to a single global scalar).
    US would enforce a single compromised global scale instead.
\end{itemize}

In Query-by-Content scenarios, such as query-by-humming or gesture retrieval, the query is generated by a human.
Humans do not maintain a consistent rate for each phase.
For example, humans rush through a familiar sequence but slow down for a new or complex sequence. It is commonly observed in a piece of music performed by a beginner. The piece's tempo is not uniform.

We introduce a novel distance measure framework, termed Piecewise Scaling Distance (PSD). 
It addresses the local scaling effect within each phase by employing a scaling factor to each phase, instead of using a single scaling factor for the whole time series.
It releases the basic constraint or assumption made in US and USDTW.
%
PSD employs an existing distance metric, such as ED or DTW, to quantify the similarity of aligned segment pairs.
While the PSD framework is agnostic to the underlying metric, this study focuses on its two fundamental instantiations:
\begin{itemize}
    \item PSED, which employs ED to compute the similarity of aligned segment pairs.
    \item PSDTW, which employs DTW to compute the similarity of aligned segment pairs.
\end{itemize}

In the formulation that follows, we utilize PSDTW as the running example. 
PSDTW generalizes PSED.
The PSED formulation can be trivially derived from it.

\subsection{Piecewise Scaling \& Dynamic Time Warping (PSDTW)}
\noindent\RuninHead{Problem formulation} 
To simplify the discussion, we focus on the comparison between $Q$ and the entire sequence $C$, rather than a prefix of $C$. 
Note that this formulation can be generalized to prefix matching as in Definition~\ref{def:us} and Definition~\ref{def:usdtw}.
% The most similar prefix of $C$ under PSDTW can be identified in a similar fashion by iterating through all candidate prefixes, as in Equation~\ref{eq:us} and Equation~\ref{eq:usdtw}.

Given two sequences $Q$ and $C$, where $Q$ is not longer than $C$, $|Q| = m \leq |C| = n$, and the number of segments or pieces $P$ allowed, our goal is to segmentalize both $Q$ and $C$ into $P$ contiguous segments automatically in a way that minimize the total sum of DTW distance of aligned segment pairs with interpolation. 

\begin{definition}[Piecewise Scaling \& Dynamic Time Warping (PSDTW)]
    \label{def:psdtw}
    With the same notations defined in Definition~\ref{def:usdtw},
    % https://tex.stackexchange.com/questions/145657/align-equation-left
    % https://tex.stackexchange.com/questions/172635/how-to-add-a-line-break-in-math-mode-but-number-the-whole-as-one-formula
    % https://tex.stackexchange.com/questions/46189/how-do-i-add-a-line-break-in-display-math-mode
    % https://tex.stackexchange.com/questions/80460/expression-under-summation-on-multiple-lines
    \begin{equation}
        \label{eq:psdtw}
        \begin{split}
            & \operatorname{PSDTW}_r(Q, C, l, L, P) = \\
            & \min_{\substack{i_1 < i_2 < \dots < i_{P+1} \\ j_1 < j_2 < \dots < j_{P+1}}} \sum_{p=1}^{P} \operatorname{DTW}_r(Q{(i_p+1:i_{p+1})}^L, \\
            & \qquad \qquad \qquad \qquad \qquad \qquad C{(j_p+1:j_{p+1})}^L)
        \end{split}
    \end{equation}
    , where $i_1 = 0$, $i_{P+1} = m$, $j_1 = 0$, $j_{P+1} = n$ and the setting of $L$ will be discussed later. 
\end{definition}

Essentially, $L$ needs to be at least the length of all segments to preserve all the points by up-sampling.

We refer to Figure~\ref {fig:psdtw-intuition} to clarify Equation~\ref{eq:psdtw}.
Given two sequences $Q$ and $C$, with the aid of different colors and the dashed lines, we observe that $Q$ consists of three segments while $C$ consists of four segments, with the first three segments of $C$ similar to those of $Q$.
They form three segment pairs.
The scaling factor used in each segment pair is determined from the length of the two subsequences involved, i.e., $(i_{p+1}-i_{p})/(j_{p+1}-j_p)$.
These three parts have different scaling factors.
For example, the first part in $C$ is the stretched version of that in $Q$.
The second part in $C$ is the compressed version of that in $Q$.

Equation~\ref{eq:psdtw} can be formulated in a recurrence relation as follows.
Let $D[i, j, p]$ be the minimum cost to align the first $i$ points in $Q$ (i.e, $Q(1:i)$) with the first $j$ points in $C$ (i.e., $C(1:j)$) using exactly $p$ segments:

\begin{equation}
\label{eq:psdtw-recurrence}
\begin{split}
    D[i, j, p] = \min_{\substack{i' < i \\ j' < j}} \bigg\{ & D[i', j', p - 1] \\
    & + \operatorname{DTW}_r(Q{(i'+1: i)}^L, C{(j'+1: j)}^L) \bigg\}
\end{split}
\end{equation}

\noindent\RuninHead{Naive PSDTW} 

\input{../algorithms/psdtw}
\input{../algorithms/psdtw-recurrence}
Our goal is $D[m,n,P]$.
Equation~\ref{eq:psdtw-recurrence} can be solved exactly by dynamic programming (DP).
The base case is $D[0,0,0] = 0$.
It refers to the zero cost to align the first $0$ point (i.e., the empty prefix) of $Q$ with that of $C$.
Other cells in $D$ are first initialized with $\infty$.
They are calculated using a bottom-up approach via Equation~\ref{eq:psdtw-recurrence}.
A straightforward implementation in DP is shown in Algorithm~\ref{alg:psdtw}.
Line 6 is achieved by looping all the previous indices of the current $i$ and $j$ as in Algorithm~\ref{alg:psdtw-recurrence}. 

We explain the lines in  Algorithm~\ref{alg:psdtw-recurrence}.
Line 3 retrieves the accumulated distance cost from the beginning up to the endpoints $(i', j')$, and saves it as $\textit{dist}_{\text{prev}}$. 
Line 4 considers the current aligned segment pair, which consists of $Q(i'+1:i)$ and $C(j'+1,j)$, and they are interpolated to the length $L$. The DTW distance of this pair is calculated and saved as $\textit{}{dist}_{\text{seg}}$.

We now analyze the time complexity of Algorithm~\ref{alg:psdtw}.
There are $Pmn$ entries in $D$.
The $min$ operator in line 6 takes $\mathcal{O}(mn)$.
Hence, the time complexity of Algorithm~\ref{alg:psdtw} is $\mathcal{O}(Pm^2n^2) = \mathcal{O}(Pn^4)$, multiplied by the running time of the DTW.
It is slow, which prevents us from using it in practice.
To note, we use $r$ in a fraction instead of a fixed integer here.
This allows the deviation tolerance to scale adaptively with pieces of varying lengths.

\subsection{Speedup Techniques}

\noindent\RuninHead{Length constraints of the segment}
\input{../algorithms/psdtw-constrained-initial}
\input{../algorithms/psdtw-constrained}
A way to reduce complexity and to prevent pathological segment pairs is to limit the possible segment lengths that are considered
by constraining the minimum and maximum lengths of segments.
It is similar to constrained DTW, in which we limit the search space of the warping path as in Figure~\ref{fig:dtw-matrix}.
The version of PSDTW that considers the segment constraint is termed constrained PSDTW (cPSDTW).
It is shown in Algorithm~\ref{alg:psdtw-constrained}.
The uncolored part shows the main logic, while the colored part shows the speedup techniques, which will be explained later.

We initialize in Algorithm~\ref{alg:psdtw-constrained-initial}.
For a given number of segments $P$, the expected length of each segment in $Q$ and $C$ would be $m/P$ and $n/P$, respectively.
For $Q$, we set the minimum possible segment length $L_{\mathrm{gmin}}^Q$ to be $\ceil{(m/P)/\sqrt{l}}$ and the maximum possible length $L_{\mathrm{gmax}}^Q$ to be $\floor{(m/P)\sqrt{l}}$ in line 1 such that the scaling ratio of any two segments in $Q$ would be bounded by $l$.
It allows some deviation in the length of the segments from their expected length.
Similarly, we compute the segment constraints for $C$ in line 2.
We set the maximum segment length be the alignment factor $L$ in line 3.
We set the base case in line 5.

We fill the table $D$ in Algorithm~\ref{alg:psdtw-constrained}.
In line 3, given $p$ pieces in $Q$, the ending index of the last piece (i.e., the $p^\text{th}$ piece) will range from $(p \cdot L_{\mathrm{gmin}}^Q)$, given all the $p$ pieces are in minimum length $L_{\mathrm{gmin}}^Q$, to $\min(p \cdot L_{\mathrm{gmax}}^Q, m)$, given all the $p$ pieces are in maximum length $L_{\mathrm{gmax}}^Q$.

\input{../figures/L_Q-L_C-relationship}
In line 4, we enumerate for all the allowed lengths $L^Q$.
For the segment with length $L^Q$ in $Q$, the length $L^C$ of the corresponding aligned segment in $C$ will have a range from $L_{\min}^C$ to $L_{\max}^C$, as defined in lines 7--8, such that the ratio of $L^Q$ and $L^C$ would be bounded by $l$.
Because $L^Q$ and $L^C$ increase in line 4 and line 14, 
and the $i$ and $j$ are fixed by the outer loop, in line 3 and line 13, respectively, the $i'$ and $j'$ decrease correspondingly
It is visualized in Figure~\ref{fig:L_Q-L_C-relationship}.
%
A segment in $Q$ with ending index $i$ and starting index $i'+1$ would be compared to a set of segments in $C$, all of which have a fixed end at $j$ and a decreasing starting index, starting at $j'+1$. 
For example, the starting index of the first segment with being compared is $j' + 1$, which has length $L^C$, and that of the second segment is $j'$, which has length $L^C + 1$, as in Figure~\ref{fig:L_Q-L_C-relationship}.

In line 18, we terminate the current iteration if there are no previously valid segment pairs (i.e., $\mathit{dist}_\mathrm{prev} = \infty$).

In line 22, if the accumulated cost $\textit{dist}_{\text{prev}}$ exceeds the current best so far, we stop the current iteration as the resulting $(\mathit{dist}_{\mathrm{prev}}+\mathit{dist}_{\mathrm{seg}})$ is guaranteed to be greater than the current best so far, which is stored in $D[i, j, p]$.

To be consistent with the result of using the lower bound speedup technique, which will be introduced later, we compute the DTW in the reverse manner in line 33.
Due to the nearest neighbor interpolation, $\operatorname{DTW}_r(Q'^L, C'^L)$ may not equal to $\operatorname{DTW}_r(\operatorname{rev}(Q')^L, \operatorname{rev}(C')^L)$.

In line 35, we also save the pairs ($i', j'$) that serve as cutting points between segments to obtain the segmentation result.

\noindent\RuninHead{Parallel computing} 
We observe that the recurrence relation for the state $D[i, j, p]$ at stage $p$ depends exclusively on the states computed at stage $p-1$, as shown in Equation~\ref{eq:psdtw-recurrence}.
There are no stage dependencies over indices $i$ and $j$.
It allows us to parallelize the loops over indices $i$ and $j$ on lines 3 and 13.
In the following experimental section, we distribute the i-loop iterations (i.e., line 3 in Algorithm~\ref{alg:psdtw-constrained}, which is colored in \blue{blue}) across available threads only because there are already sufficient iterations from the i-loop to fill the available threads.
There are $\left(\min(p \cdot L_{\mathrm{gmax}}^Q, m) - (p \cdot L_{\mathrm{gmin}}^Q) + 1\right)$ iterations from the i-loop.
The parallel execution of the $i$-loop is implemented by \texttt{prange} in \texttt{Numba} in Python.

\noindent\RuninHead{Early Abandoning in nearest neighbor search} 
To accelerate the nearest neighbor search (or top-$k$ search) for a query $Q$ on a candidate set, we employ an early abandoning strategy. 
It prunes the search branch within the PSD computation of a specific candidate $C$ as soon as the result corresponding to this search branch is determined to be suboptimal. 
We maintain a variable, $\mathrm{bsf}$ (best-so-far), which represents the minimum final distance among the candidates processed with $Q$ so far. 
$\mathrm{bsf}$ serves as an upper-bound threshold.
During the evaluation of a new candidate $C$, we monitor the accumulated partial distance, $\mathit{dist}_{\mathrm{prev}}$. 
If $\mathit{dist}_{\mathrm{prev}}$ exceeds $\mathrm{bsf}$, the corresponding final distance is guaranteed to exceed $\mathrm{bsf}$.
In such cases, the current search branch is immediately terminated. 
The implementation of this pruning mechanism is detailed in lines 20--21 in Algorithm~\ref{alg:psdtw-constrained}, which are colored in \orange{orange}.
In the case of top-$k$ search, we must maintain the top-$k$ final distances and use the $k$-th distance as the threshold.

\noindent\RuninHead{Lower bound} 

\input{../algorithms/psdtw-reuse-reaches}
When we use DTW as a routine in PSD, the computation of the DTW of the interpolated segment can be sped up by computing $\lbShen$ for the lower bound.
From Figure~\ref{fig:L_Q-L_C-relationship}, we observe that a segment of $Q$, with length $L^Q$, is compared to a set of growing segments of $C$, with a fixed end at $j$.
The length of these segments is from $L_{\min}^C$ to $L_{\max}^C$, as indicated in line 14 in Algorithm~\ref{alg:psdtw-constrained}.
They share the same suffix with length $L_{\min}^C$.
It encourages us to view both $Q$ and $C$ reversely.
The reversed segments are denoted as $Q'$ and $C'$, as in lines 6 and 16 in Algorithm~\ref{alg:psdtw-constrained}.
In this reversed view, they share the same prefix with length $L_{\min}^C$.
Hence, we construct an indexed collection $\tilde{\mathbbm{Q}}$ for $Q'$ with the maximum length of the segments being compared in $C$, which is $L^C_{\max}$, as in lines 10--12.

In lines 24--27, we first compute the lower bound between $Q'$ and the shortest segment of $C$.
We add the minimum possible contribution of each $c'$ to the distance contributed by the first alignment, which is $\textit{lb} = (c'_1 - q'_1)$.
For the lower bound of the subsequent segments, we compute them incrementally in line 29.
Because the last point of segment $C'$ must map to the last point of $Q'$, we further tighten the lower bound by using the last alignment in line 30 instead.

Furthermore, we can reduce the computational overhead of constructing the sorted reaches $\tilde{\mathbbm{q}_k}$ (lines 9--12). As illustrated in Figure~\ref{fig:L_Q-L_C-relationship}, the segment of $Q$ involved in the comparison grows incrementally. Since the reversed versions of these segments share a common prefix, the sorted reaches $\tilde{\mathbbm{q}_k}$ computed for a segment $Q'$ of length $L^Q$ can be reused to compute those for the subsequent segments. 
This optimization is detailed in Algorithm~\ref{alg:psdtw-reuse-reaches}, with the new components highlighted in {\color{blue}blue}. 
It is important to note that because $r'$ is a function of $L^Q$, and the construction of $\tilde{\mathbbm{q}_k}$ depends on $r$, reuse is limited to cases where $r'$ remains constant.
We construct reaches $\tilde{\mathbbm{q}_k}$ from the sketch in lines 20--22 and keep track of the $r'$ used for construction in line 23.
If $r'$ remains constant, we can use previously computed reaches $\tilde{\mathbbm{q}_k}$ to compute the new set of reaches $\tilde{\mathbbm{q}_k}$.
Since the ending index of reaches depends on $\min(\floor{kl} + r', L^Q)$, we need to check whether we have a new ending index when $L^Q$ increases.
If the ending index has been changed, we need to add the new data points $q'_{e_\mathrm{new}}$ to the sorted sequence $\tilde{\mathbbm{q}}_k$, as in line 15.

$L_{\max}^C$ depends of $L^Q$.
If $L_{\max}^C$ increase because $L^Q$ increase, we construct the new reach $\tilde{\mathbbm{q}}_k$ and sort it in lines 16--18.

\subsection{Guided Distance}

For faster computation, one would want to use a distance measure with linear complexity, such as ED, as the base measure for PSD.
While PSED is effective for identifying phase-scaling changes, certain applications require capturing complex properties within those segments that ED cannot handle. 
There are two ways to address it.
One approach is to use an alternative distance measure that captures these complex properties as the base distance for computing the PSD, such as DTW.
But PSDTW is slower than PSED.
The other approach is to use the segmentation result returned by PSED. 
To address this, we propose a two-stage framework in which PSED-derived segmentation guides the application of advanced distance metrics $M$.
Let $\mathcal{P}^* = \{(i_1, j_1), (i_2, j_2), \dots, (i_{P+1}, j_{P+1})\}$ be the set of optimal cut points on $Q$ and $C$ obtained by minimizing the PSED. 
We utilize $\mathcal{P}^*$ to partition both series into $P$ aligned pairs of segments. 
The final distance, denoted as $M^{\text{PSED}}$, is calculated by summing the distances of these pairs using a target metric $M$:

\begin{equation} 
\label{eq:guided-dist}
M^{\text{PSED}}(Q, C) = \sum_{p=1}^{P} M(Q_{p}^L, C_{p}^L)
\end{equation}
, where $Q_{p} = Q(i_p + 1: i_{p+1})$ and $C_{p} = C(j_p + 1 : j_{p+1})$.


